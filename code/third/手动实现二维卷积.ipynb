{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "二维卷积.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AgGvmh65pKbf"
      },
      "outputs": [],
      "source": [
        "!unzip /content/traffic_data.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "from matplotlib import pyplot as plt\n",
        "import torch.utils.data as Data\n",
        "from PIL import Image\n",
        "import os\n",
        "from torch import nn\n",
        "import torch.optim as optim\n",
        "from torch.nn import init\n",
        "import torch.nn.functional as F\n",
        "import time\n",
        "import torchvision\n",
        "from torchvision import transforms,datasets\n",
        "from shutil import copy, rmtree\n",
        "import json"
      ],
      "metadata": {
        "id": "NqS6sCNbqApO"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mk_file(file_path: str):\n",
        "  if os.path.exists(file_path):\n",
        "  # 如果文件夹存在，则先删除原文件夹在重新创建\n",
        "    rmtree(file_path)\n",
        "  os.makedirs(file_path)\n",
        "def split_data():\n",
        "  random.seed(0)\n",
        "  # 将数据集中25%的数据划分到验证集中\n",
        "  split_rate = 0.25\n",
        "  data_root = os.getcwd()\n",
        "  origin_car_path = os.path.join(data_root, \"traffic_data\")\n",
        "  assert os.path.exists(origin_car_path), \"path '{}' does not exist.\".format(origin_car_path)\n",
        "  car_class = [cla for cla in os.listdir(origin_car_path) if os.path.isdir(os.path.join(origin_car_path, cla))]\n",
        "\n",
        "  # 建立保存训练集的文件夹\n",
        "  train_root = os.path.join(data_root, \"train\")\n",
        "  mk_file(train_root)\n",
        "  for cla in car_class:\n",
        "  # 建立每个类别对应的文件夹\n",
        "    mk_file(os.path.join(train_root, cla))\n",
        "\n",
        "  # 建立保存验证集的文件夹\n",
        "  test_root = os.path.join(data_root, \"test\")\n",
        "  mk_file(test_root)\n",
        "  for cla in car_class:\n",
        "  # 建立每个类别对应的文件夹\n",
        "    mk_file(os.path.join(test_root, cla))\n",
        "  for cla in car_class:\n",
        "    cla_path = os.path.join(origin_car_path, cla)\n",
        "    images = os.listdir(cla_path)\n",
        "    num = len(images)\n",
        "    # 随机采样验证集的索引\n",
        "    eval_index = random.sample(images, k=int(num*split_rate))\n",
        "    for index, image in enumerate(images):\n",
        "      if image in eval_index:\n",
        "      # 将分配至验证集中的文件复制到相应目录\n",
        "        image_path = os.path.join(cla_path, image)\n",
        "        new_path = os.path.join(test_root, cla)\n",
        "        copy(image_path, new_path)\n",
        "      else:\n",
        "      # 将分配至训练集中的文件复制到相应目录\n",
        "        image_path = os.path.join(cla_path, image)\n",
        "        new_path = os.path.join(train_root, cla)\n",
        "        copy(image_path, new_path)\n",
        "      print(\"\\r[{}] processing [{}/{}]\".format(cla, index+1, num), end=\"\")  # processing bar\n",
        "  print(\"processing done!\")\n",
        "split_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8HVbg109qz-Q",
        "outputId": "2deebe16-8ff6-4679-d567-2282b068fce4"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[car] processing [779/779]processing done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"using {} device.\".format(device))\n",
        "\n",
        "data_transform = {\"train\": transforms.Compose([transforms.Resize((64,64)),transforms.RandomHorizontalFlip(),transforms.ToTensor(),transforms.Normalize((0.5,0.5,0.5),\n",
        "(0.5,0.5,0.5))]),\"test\": transforms.Compose([transforms.Resize((64,64)),transforms.ToTensor(),transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])}\n",
        "\n",
        "\n",
        "image_path = os.getcwd()\n",
        "print(image_path)\n",
        "train_dataset = datasets.ImageFolder(root=os.path.join(image_path,\"train\"),transform = data_transform[\"train\"])\n",
        "train_num = len(train_dataset)\n",
        "print(train_num)\n",
        "\n",
        "batch_size = 32\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset,batch_size = batch_size,shuffle = True,num_workers = 0)\n",
        "\n",
        "test_dataset = datasets.ImageFolder(root=os.path.join(image_path,\"test\"),transform = data_transform[\"test\"])\n",
        "\n",
        "test_num = len(test_dataset)\n",
        "print(test_num)#val_num = 364\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset,batch_size = batch_size,shuffle=False,num_workers = 0)\n",
        "print(\"using {} images for training, {} images for validation .\".format(train_num,test_num))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZ-JxMOVvjtL",
        "outputId": "c2a438f8-516c-41cb-ddec-2b0290a872a5"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using cuda:0 device.\n",
            "/content\n",
            "1019\n",
            "338\n",
            "using 1019 images for training, 338 images for validation .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "8cbiW76T4Gpx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 二维卷积"
      ],
      "metadata": {
        "id": "gx1Q1xEtptYi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 手写二维卷积"
      ],
      "metadata": {
        "id": "81mh8JD1x_TB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#自定义单通道卷积  \n",
        "def corr2d(X,K):  \n",
        "  '''\n",
        "  X:输入，shape (batch_size,H,W) \n",
        "  K:卷积核，shape (k_h,k_w) \n",
        "  单通道 \n",
        "  '''  \n",
        "  batch_size,H,W = X.shape  \n",
        "  k_h, k_w = K.shape  \n",
        "  #初始化结果矩阵  \n",
        "  Y = torch.zeros((batch_size,H - k_h + 1,W- k_w + 1)).to(device)\n",
        "  for i in range(Y.shape[1]):  \n",
        "    for j in range(Y.shape [2]):  \n",
        "      Y[:,i,j] = (X[:,i:i+k_h,j:j+k_w]* K).sum()\n",
        "  return Y  \n",
        "#自定义多通道卷积  \n",
        "def corr2d_mu1ti_in(X, K):  \n",
        "  #输入X:维度(batch_size,C_in,H, W)  \n",
        "  #卷积核K:维度(C_in,k_h,k_w)  \n",
        "  #输出:维度(batch_size,H_out,W_out)  \n",
        "  #先计算第一通道  \n",
        "  res = corr2d(X[:,0,:,:], K[0,:,:])\n",
        "  for i in range(1, X.shape[1]):  \n",
        "  #按通道相加  \n",
        "    res += corr2d(X[:,i,:,:], K[i,:,:])\n",
        "  return res  \n",
        "\n",
        "#自定义多个多通道卷积  \n",
        "def corr2d_multi_in_out(X, K):  \n",
        "  # X: shape (batch_size,C_in,H,W)  \n",
        "  # K: shape (C_out,C_in,h,w)  \n",
        "  # Y: shape(batch_size,C_out,H_out,W_out)  \n",
        "  return torch.stack([corr2d_mu1ti_in(X, k) for k in K],dim=1)\n",
        "\n"
      ],
      "metadata": {
        "id": "NjS53gifyCRH"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 自定义卷积层"
      ],
      "metadata": {
        "id": "kH4VJOw_ypbk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyConv2D(nn.Module):  \n",
        "  def __init__(self,in_channels, out_channels,kernel_size):  \n",
        "    super(MyConv2D,self).__init__()  \n",
        "    #初始化卷积层的2个参数:卷积核、偏差  \n",
        "    #isinstance判断类型  \n",
        "    if isinstance(kernel_size,int):  \n",
        "      kernel_size = (kernel_size,kernel_size)  \n",
        "      self.weight = nn.Parameter(torch.randn((out_channels, in_channels) + kernel_size)).to(device)  \n",
        "      self.bias = nn.Parameter(torch.randn(out_channels,1,1)).to(device)  \n",
        "  def forward(self,x):    #x:输入图片，维度(batch_size,C_in,H,W)\n",
        "    res =  corr2d_multi_in_out(x,self.weight) + self.bias\n",
        "    return res"
      ],
      "metadata": {
        "id": "VORTKVHly02l"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 定义卷积网络"
      ],
      "metadata": {
        "id": "xZDDY_aVzOGG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyConvModule(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(MyConvModule,self).__init__()\n",
        "    #定义一层卷积层\n",
        "    self.conv = nn.Sequential(\n",
        "      MyConv2D(in_channels = 3,out_channels = 32,kernel_size = 3),\n",
        "      nn.BatchNorm2d(32),\n",
        "      # inplace-选择是否进行覆盖运算\n",
        "      nn.ReLU(inplace=True))\n",
        "      #输出层,将通道数变为分类数量\n",
        "    self.fc = nn.Linear(32,3)\n",
        "  def forward(self,x):\n",
        "    #图片经过一层卷积，输出维度变为(batch_size,C_out,H,W)\n",
        "    out = self.conv(x)\n",
        "    #使用平均池化层将图片的大小变为1x1,第二个参数为最后输出的长和宽（这里默认相等了）64-3/1 + 1 = 62\n",
        "    out = F.avg_pool2d(out,62)\n",
        "    #将张量out从shape batchx32x1x1 变为 batch x32\n",
        "    out = out.squeeze()\n",
        "    #输入到全连接层将输出的维度变为3\n",
        "    out = self.fc(out)\n",
        "    return out"
      ],
      "metadata": {
        "id": "YV6F1qIjzQxN"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 训练函数"
      ],
      "metadata": {
        "id": "BNOY1vaKzt59"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.001\n",
        "epochs = 5\n",
        "num_class = 3\n",
        "#初始化模型\n",
        "net = MyConvModule().to(device)\n",
        "#使用多元交叉熵损失函数\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "#使用Adam优化器\n",
        "optimizer = optim.Adam(net.parameters(),lr = lr)\n",
        "\n",
        "def train_epoch(net, data_loader, device):\n",
        "  net.train() #指定当前为训练模式\n",
        "  train_batch_num = len(data_loader) #记录共有多少个batch\n",
        "  total_1oss = 0 #记录Loss\n",
        "  correct = 0 #记录共有多少个样本被正确分类\n",
        "  sample_num = 0 #记录样本总数\n",
        "  #遍历每个batch进行训练\n",
        "  for batch_idx, (data,target) in enumerate (data_loader):\n",
        "    t1 = time.time()\n",
        "    #将图片放入指定的device中\n",
        "    data = data.to(device).float()\n",
        "    #将图片标签放入指定的device中\n",
        "    target = target.to(device).long()\n",
        "    #将当前梯度清零\n",
        "    optimizer.zero_grad()\n",
        "    #使用模型计算出结果\n",
        "    output = net(data)\n",
        "    #计算损失\n",
        "    loss = loss_func(output, target.squeeze())\n",
        "    #进行反向传播\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    #累加loss\n",
        "    total_1oss += loss.item()\n",
        "    #找出每个样本值最大的idx,即代表预测此图片属于哪个类别\n",
        "    prediction = torch.argmax(output, 1)\n",
        "    #统计预测正确的类别数量\n",
        "    correct += (prediction == target).sum().item()\n",
        "    #累加当前的样本总数\n",
        "    sample_num += len(prediction)\n",
        "    #if batch_idx//5 ==0:\n",
        "    t2 = time.time()\n",
        "    print(\"processing:{}/{},消耗时间{}s\".format(batch_idx+1,len(data_loader),t2-t1))\n",
        "  #计算平均loss与准确率\n",
        "  loss = total_1oss / train_batch_num\n",
        "  acc = correct / sample_num\n",
        "  return loss, acc\n",
        "\n",
        "def test_epoch(net, data_loader, device):\n",
        "  net.eval() #指定当前模式为测试模式\n",
        "  test_batch_num = len(data_loader)\n",
        "  total_loss = 0\n",
        "  correct = 0\n",
        "  sample_num = 0\n",
        "  #指定不进行梯度变化\n",
        "  with torch.no_grad():\n",
        "    for batch_idx, (data, target) in enumerate(data_loader):\n",
        "      data = data.to(device).float()\n",
        "      target = target.to(device).long()\n",
        "      output = net(data)\n",
        "      loss = loss_func(output, target)\n",
        "      total_loss += loss.item( )\n",
        "      prediction = torch.argmax(output, 1)\n",
        "      correct += (prediction == target).sum().item()\n",
        "      sample_num += len(prediction)\n",
        "  loss = total_loss / test_batch_num\n",
        "  acc = correct / sample_num\n",
        "  return loss,acc"
      ],
      "metadata": {
        "id": "4BrYe99yz14a"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 训练"
      ],
      "metadata": {
        "id": "V3F9Ph1_2fhm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## 存储每一个epoch的loss与acc的变化，便于后面可视化\n",
        "train_loss_list = []\n",
        "train_acc_list = []\n",
        "test_loss_list = []\n",
        "test_acc_list = []\n",
        "time_list = []\n",
        "timestart = time.time()\n",
        "print(device)\n",
        "#进行训练\n",
        "for epoch in range(epochs):\n",
        "  #每一个epoch的开始时间\n",
        "  time_start = time.time()\n",
        "  #在训练集上训练  \n",
        "  train_loss, train_acc = train_epoch(net,data_loader=train_loader, device=device)\n",
        "  #在测试集上验证\n",
        "  test_loss, test_acc = test_epoch(net,data_loader=test_loader, device=device)\n",
        "  #每一个epoch的结束时间\n",
        "  time_end = (time.time() - time_start)\n",
        "  #保存各个指际\n",
        "  train_loss_list.append(train_loss)  \n",
        "  train_acc_list.append(train_acc )  \n",
        "  test_loss_list.append(test_loss)  \n",
        "  test_acc_list.append(test_acc)  \n",
        "  time_list.append(time_end)  \n",
        "  print('epoch %d, train_loss %.6f,test_loss %.6f,train_acc %.6f,test_acc %.6f,Time used %.6fs'%(epoch+1, train_loss,test_loss,train_acc,test_acc,time_end))  \n",
        "#计算总时间  \n",
        "timesum = (time.time() - timestart)  \n",
        "print('The total time is %fs',timesum) \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zRaAoZ92hIF",
        "outputId": "accd5203-8f00-4643-c26f-662f285c73c6"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n",
            "processing:1/32,消耗时间58.37450075149536s\n",
            "processing:2/32,消耗时间60.53974366188049s\n",
            "processing:3/32,消耗时间59.64996123313904s\n",
            "processing:4/32,消耗时间59.738276720047s\n",
            "processing:5/32,消耗时间59.29375863075256s\n",
            "processing:6/32,消耗时间59.90777635574341s\n",
            "processing:7/32,消耗时间59.40642046928406s\n",
            "processing:8/32,消耗时间59.51416754722595s\n",
            "processing:9/32,消耗时间58.91418790817261s\n",
            "processing:10/32,消耗时间58.90377998352051s\n",
            "processing:11/32,消耗时间59.90839457511902s\n",
            "processing:12/32,消耗时间59.37030363082886s\n",
            "processing:13/32,消耗时间59.29256749153137s\n",
            "processing:14/32,消耗时间58.58264088630676s\n",
            "processing:15/32,消耗时间59.5806519985199s\n",
            "processing:16/32,消耗时间58.380335092544556s\n",
            "processing:17/32,消耗时间59.41806697845459s\n",
            "processing:18/32,消耗时间59.03585457801819s\n",
            "processing:19/32,消耗时间59.53761959075928s\n",
            "processing:20/32,消耗时间58.703988790512085s\n",
            "processing:21/32,消耗时间59.773438453674316s\n",
            "processing:22/32,消耗时间58.5155394077301s\n",
            "processing:23/32,消耗时间58.56944799423218s\n",
            "processing:24/32,消耗时间59.14865970611572s\n",
            "processing:25/32,消耗时间58.77095937728882s\n",
            "processing:26/32,消耗时间59.23814153671265s\n",
            "processing:27/32,消耗时间58.34639883041382s\n",
            "processing:28/32,消耗时间59.0519483089447s\n",
            "processing:29/32,消耗时间58.35476088523865s\n",
            "processing:30/32,消耗时间58.827638387680054s\n",
            "processing:31/32,消耗时间58.49249744415283s\n",
            "processing:32/32,消耗时间58.7238130569458s\n",
            "epoch 1, train_loss 1.008204,test_loss 0.872223,train_acc 0.574092,test_acc 0.573964,Time used 2048.788409s\n",
            "processing:1/32,消耗时间56.98367476463318s\n",
            "processing:2/32,消耗时间58.44130516052246s\n",
            "processing:3/32,消耗时间58.23518228530884s\n",
            "processing:4/32,消耗时间58.81710386276245s\n",
            "processing:5/32,消耗时间58.394028425216675s\n",
            "processing:6/32,消耗时间58.942564725875854s\n",
            "processing:7/32,消耗时间58.418081760406494s\n",
            "processing:8/32,消耗时间58.51024580001831s\n",
            "processing:9/32,消耗时间59.035080432891846s\n",
            "processing:10/32,消耗时间58.2522988319397s\n",
            "processing:11/32,消耗时间58.89191699028015s\n",
            "processing:12/32,消耗时间59.106364488601685s\n",
            "processing:13/32,消耗时间59.06628084182739s\n",
            "processing:14/32,消耗时间58.67104935646057s\n",
            "processing:15/32,消耗时间59.12050986289978s\n",
            "processing:16/32,消耗时间58.565677881240845s\n",
            "processing:17/32,消耗时间59.31495809555054s\n",
            "processing:18/32,消耗时间58.25556945800781s\n",
            "processing:19/32,消耗时间59.02812433242798s\n",
            "processing:20/32,消耗时间58.404383420944214s\n",
            "processing:21/32,消耗时间58.48125195503235s\n",
            "processing:22/32,消耗时间58.992647886276245s\n",
            "processing:23/32,消耗时间58.75950336456299s\n",
            "processing:24/32,消耗时间57.87374424934387s\n",
            "processing:25/32,消耗时间57.315924882888794s\n",
            "processing:26/32,消耗时间57.703513383865356s\n",
            "processing:27/32,消耗时间57.38701915740967s\n",
            "processing:28/32,消耗时间57.92354702949524s\n",
            "processing:29/32,消耗时间57.40398383140564s\n",
            "processing:30/32,消耗时间57.789071559906006s\n",
            "processing:31/32,消耗时间58.71521711349487s\n",
            "processing:32/32,消耗时间57.82839560508728s\n",
            "epoch 2, train_loss 0.968438,test_loss 0.871538,train_acc 0.574092,test_acc 0.573964,Time used 2021.921656s\n",
            "processing:1/32,消耗时间55.922165870666504s\n",
            "processing:2/32,消耗时间57.21617078781128s\n",
            "processing:3/32,消耗时间57.23987650871277s\n",
            "processing:4/32,消耗时间57.740800857543945s\n",
            "processing:5/32,消耗时间57.249831438064575s\n",
            "processing:6/32,消耗时间57.18389964103699s\n",
            "processing:7/32,消耗时间57.77225470542908s\n",
            "processing:8/32,消耗时间57.56087851524353s\n",
            "processing:9/32,消耗时间57.93946075439453s\n",
            "processing:10/32,消耗时间57.37757992744446s\n",
            "processing:11/32,消耗时间58.0185284614563s\n",
            "processing:12/32,消耗时间57.24243211746216s\n",
            "processing:13/32,消耗时间57.77149748802185s\n",
            "processing:14/32,消耗时间57.237688064575195s\n",
            "processing:15/32,消耗时间58.16376996040344s\n",
            "processing:16/32,消耗时间57.15403628349304s\n",
            "processing:17/32,消耗时间57.850616216659546s\n",
            "processing:18/32,消耗时间57.42771124839783s\n",
            "processing:19/32,消耗时间57.30182147026062s\n",
            "processing:20/32,消耗时间58.10705518722534s\n",
            "processing:21/32,消耗时间57.53772950172424s\n",
            "processing:22/32,消耗时间58.18170690536499s\n",
            "processing:23/32,消耗时间57.52262234687805s\n",
            "processing:24/32,消耗时间58.06475830078125s\n",
            "processing:25/32,消耗时间57.59455704689026s\n",
            "processing:26/32,消耗时间58.15741491317749s\n",
            "processing:27/32,消耗时间57.59144115447998s\n",
            "processing:28/32,消耗时间58.158854484558105s\n",
            "processing:29/32,消耗时间57.484835386276245s\n",
            "processing:30/32,消耗时间57.81665277481079s\n",
            "processing:31/32,消耗时间57.72121477127075s\n",
            "processing:32/32,消耗时间57.42241621017456s\n",
            "epoch 3, train_loss 0.965908,test_loss 0.874960,train_acc 0.574092,test_acc 0.573964,Time used 1996.081613s\n",
            "processing:1/32,消耗时间55.61747193336487s\n",
            "processing:2/32,消耗时间57.00887751579285s\n",
            "processing:3/32,消耗时间57.19240403175354s\n",
            "processing:4/32,消耗时间57.53658199310303s\n",
            "processing:5/32,消耗时间57.02319383621216s\n",
            "processing:6/32,消耗时间57.15152978897095s\n",
            "processing:7/32,消耗时间57.81594109535217s\n",
            "processing:8/32,消耗时间56.92609643936157s\n",
            "processing:9/32,消耗时间57.57446622848511s\n",
            "processing:10/32,消耗时间57.252285957336426s\n",
            "processing:11/32,消耗时间57.60515737533569s\n",
            "processing:12/32,消耗时间57.053081035614014s\n",
            "processing:13/32,消耗时间57.80773568153381s\n",
            "processing:14/32,消耗时间57.17650365829468s\n",
            "processing:15/32,消耗时间57.731385707855225s\n",
            "processing:16/32,消耗时间57.035945653915405s\n",
            "processing:17/32,消耗时间57.376519203186035s\n",
            "processing:18/32,消耗时间57.83098530769348s\n",
            "processing:19/32,消耗时间57.077186584472656s\n",
            "processing:20/32,消耗时间57.43135404586792s\n",
            "processing:21/32,消耗时间57.163321018218994s\n",
            "processing:22/32,消耗时间57.4702730178833s\n",
            "processing:23/32,消耗时间57.23469519615173s\n",
            "processing:24/32,消耗时间57.63346552848816s\n",
            "processing:25/32,消耗时间57.319983959198s\n",
            "processing:26/32,消耗时间57.73303842544556s\n",
            "processing:27/32,消耗时间57.246312379837036s\n",
            "processing:28/32,消耗时间57.26881432533264s\n",
            "processing:29/32,消耗时间57.80926465988159s\n",
            "processing:30/32,消耗时间57.375473976135254s\n",
            "processing:31/32,消耗时间61.7072217464447s\n",
            "processing:32/32,消耗时间63.20485520362854s\n",
            "epoch 4, train_loss 0.965708,test_loss 0.876983,train_acc 0.574092,test_acc 0.573964,Time used 2009.469435s\n",
            "processing:1/32,消耗时间62.03445887565613s\n",
            "processing:2/32,消耗时间62.67927432060242s\n",
            "processing:3/32,消耗时间61.68992304801941s\n",
            "processing:4/32,消耗时间62.64741134643555s\n",
            "processing:5/32,消耗时间62.26377487182617s\n",
            "processing:6/32,消耗时间62.842838525772095s\n",
            "processing:7/32,消耗时间62.94910669326782s\n",
            "processing:8/32,消耗时间62.81125068664551s\n",
            "processing:9/32,消耗时间61.24392771720886s\n",
            "processing:10/32,消耗时间61.79511761665344s\n",
            "processing:11/32,消耗时间61.24862456321716s\n",
            "processing:12/32,消耗时间61.99601769447327s\n",
            "processing:13/32,消耗时间62.13016390800476s\n",
            "processing:14/32,消耗时间61.81515145301819s\n",
            "processing:15/32,消耗时间61.64829993247986s\n",
            "processing:16/32,消耗时间60.7700297832489s\n",
            "processing:17/32,消耗时间61.632373571395874s\n",
            "processing:18/32,消耗时间61.18637299537659s\n",
            "processing:19/32,消耗时间62.31479048728943s\n",
            "processing:20/32,消耗时间62.93137192726135s\n",
            "processing:21/32,消耗时间63.02206206321716s\n",
            "processing:22/32,消耗时间62.52886462211609s\n",
            "processing:23/32,消耗时间62.26798748970032s\n",
            "processing:24/32,消耗时间62.23955535888672s\n",
            "processing:25/32,消耗时间63.08983016014099s\n",
            "processing:26/32,消耗时间62.186983823776245s\n",
            "processing:27/32,消耗时间64.12598538398743s\n",
            "processing:28/32,消耗时间62.8116397857666s\n",
            "processing:29/32,消耗时间63.83643102645874s\n",
            "processing:30/32,消耗时间62.64418315887451s\n",
            "processing:31/32,消耗时间63.562018632888794s\n",
            "processing:32/32,消耗时间62.53141927719116s\n",
            "epoch 5, train_loss 0.963998,test_loss 0.875617,train_acc 0.574092,test_acc 0.573964,Time used 2163.788872s\n",
            "The total time is %fs 10240.05113863945\n"
          ]
        }
      ]
    }
  ]
}